{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PandasAI\n",
        "PandasAI is a library that makes data analysis conversational and fun again. It leverages the power of pandas dataframes combined to the most advanced LLMs to let users to data analysis in a conversational way.\n",
        "\n",
        "Similarly to what `pandas` has done (10 minutes to pandas -> https://pandas.pydata.org/docs/user_guide/10min.html), we wanted to create the most straightforward way to learn how to master PandasAI.\n",
        "\n",
        "Let's start!\n"
      ],
      "metadata": {
        "id": "5m9QRh2ofb0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "To get started, we need to install the last version of PandasAI."
      ],
      "metadata": {
        "id": "8duxIdoChr2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9szBbbJe30_",
        "outputId": "9dbf603e-259f-47bc-cb8e-ac7f8ef47c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandasai\n",
            "  Using cached pandasai-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting astor<0.9.0,>=0.8.1 (from pandasai)\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: duckdb<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pandasai) (1.1.1)\n",
            "Collecting faker<20.0.0,>=19.12.0 (from pandasai)\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from pandasai) (3.1.4)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from pandasai) (3.7.1)\n",
            "Collecting openai<2 (from pandasai)\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pandas==1.5.3 (from pandasai)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in /usr/local/lib/python3.10/dist-packages (from pandasai) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from pandasai) (2.9.2)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.0 (from pandasai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pandasai) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pandasai) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from pandasai) (2.0.35)\n",
            "Requirement already satisfied: sqlglot<26.0.0,>=25.0.3 in /usr/local/lib/python3.10/dist-packages (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai) (25.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai) (2024.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->pandasai) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->pandasai) (3.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (3.1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2->pandasai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2->pandasai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2->pandasai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai<2->pandasai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->pandasai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->pandasai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->pandasai) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4->pandasai) (3.1.1)\n",
            "Collecting sqlglotrs==0.2.6 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
            "  Downloading sqlglotrs-0.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (258 bytes)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2->pandasai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2->pandasai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2->pandasai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->pandasai) (1.16.0)\n",
            "Downloading pandasai-2.3.0-py3-none-any.whl (185 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading sqlglotrs-0.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlglotrs, python-dotenv, jiter, h11, astor, pandas, httpcore, faker, httpx, openai, pandasai\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 faker-19.13.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.2 pandas-1.5.3 pandasai-2.3.0 python-dotenv-1.0.1 sqlglotrs-0.2.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pandasai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SmartDataframe\n",
        "\n",
        "A SmartDataframe is a pandas (or polars) dataframe that inherits all the properties and methods from the `pd.DataFrame`, but also adds conversational features to it."
      ],
      "metadata": {
        "id": "EkSwZhHqfIzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai import SmartDataframe"
      ],
      "metadata": {
        "id": "DKTLrefOgGYj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can instantiate a dataframe importing from several different sources (pandas or polars dataframe, csv, xlsx or google sheets)."
      ],
      "metadata": {
        "id": "7NkkotuPf1Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing from a pandas dataframe"
      ],
      "metadata": {
        "id": "LJdaiLU9gA4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To import from a pandas dataframe, you need to import the pandas libraries and create a dataframe first."
      ],
      "metadata": {
        "id": "viepQXfkglJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LOj6QLWGLMlD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"country\": [\n",
        "        \"United States\",\n",
        "        \"United Kingdom\",\n",
        "        \"France\",\n",
        "        \"Germany\",\n",
        "        \"Italy\",\n",
        "        \"Spain\",\n",
        "        \"Canada\",\n",
        "        \"Australia\",\n",
        "        \"Japan\",\n",
        "        \"China\",\n",
        "    ],\n",
        "    \"gdp\": [\n",
        "        19294482071552,\n",
        "        2891615567872,\n",
        "        2411255037952,\n",
        "        3435817336832,\n",
        "        1745433788416,\n",
        "        1181205135360,\n",
        "        1607402389504,\n",
        "        1490967855104,\n",
        "        4380756541440,\n",
        "        14631844184064,\n",
        "    ],\n",
        "    \"happiness_index\": [6.94, 7.16, 6.66, 7.07, 6.38, 6.4, 7.23, 7.22, 5.87, 5.12],\n",
        "})"
      ],
      "metadata": {
        "id": "ugogHbQxf0Y6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since PandasAI is powered by a LLM, you should import the LLM you'd like to use for your use case.\n",
        "\n",
        "By default, if no LLM is provided, it will use BambooLLM.\n",
        "\n",
        "You can get your free API key signing up at https://pandabi.ai (you can also configure it in your .env file)"
      ],
      "metadata": {
        "id": "2bD7r0EtgsdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['PANDASAI_API_KEY'] = \"API_KEY\""
      ],
      "metadata": {
        "id": "7eRSv7WqWMHT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf = SmartDataframe(df)"
      ],
      "metadata": {
        "id": "hXFeO02JiYRC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have instantiated the LLM, we can finally instantiate the `SmartDataframe`"
      ],
      "metadata": {
        "id": "TlhiAynHiQ0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now query it in natural language"
      ],
      "metadata": {
        "id": "SEsxIYyTjHm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.chat(\"Return the top 5 countries by GDP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "0pVAthBSjEpx",
        "outputId": "856fec22-711b-4344-e8fd-8a768d353ad5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Unauthorized\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/bamboo_llm.py\", line 18, in call\n",
            "    response = self._session.post(\"/llm/chat\", json=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 37, in post\n",
            "    return self.make_request(\"POST\", path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 71, in make_request\n",
            "    raise PandasAIApiCallError(data[\"message\"])\n",
            "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, I was not able to answer your question, because of the following error:\\n\\nUnauthorized\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.chat(\"What's the sum of the gdp of the 2 unhappiest countries?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "us1r15KQjZlu",
        "outputId": "32c07506-82c7-489b-eb2d-da1c00507e5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Unauthorized\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/bamboo_llm.py\", line 18, in call\n",
            "    response = self._session.post(\"/llm/chat\", json=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 37, in post\n",
            "    return self.make_request(\"POST\", path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 71, in make_request\n",
            "    raise PandasAIApiCallError(data[\"message\"])\n",
            "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, I was not able to answer your question, because of the following error:\\n\\nUnauthorized\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sdf.last_code_generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzOEjV3LjqDF",
        "outputId": "f8007db2-79f1-4838-dad8-8627a16e749a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting a chart\n",
        "\n",
        "You can also use PandasAI to easily plot a chart"
      ],
      "metadata": {
        "id": "Pl_PQflF4_1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.chat(\"Plot a chart of the gdp by country\")"
      ],
      "metadata": {
        "id": "OeAXD-9pzlSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "5a35a80d-a850-4d9d-b52b-0565922522f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Unauthorized\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/bamboo_llm.py\", line 18, in call\n",
            "    response = self._session.post(\"/llm/chat\", json=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 37, in post\n",
            "    return self.make_request(\"POST\", path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 71, in make_request\n",
            "    raise PandasAIApiCallError(data[\"message\"])\n",
            "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, I was not able to answer your question, because of the following error:\\n\\nUnauthorized\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also provide additional instructions. For example, imagine you want to use different colors for each bar. You just need to ask to PandasAI:"
      ],
      "metadata": {
        "id": "J0lqXjcq5QyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf.chat(\"Plot a histogram of the gdp by country, using a different color for each bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "U5pJRgyY5QR2",
        "outputId": "0fc689ad-ad37-4644-ef0a-2b1741c037f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Unauthorized\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/bamboo_llm.py\", line 18, in call\n",
            "    response = self._session.post(\"/llm/chat\", json=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 37, in post\n",
            "    return self.make_request(\"POST\", path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 71, in make_request\n",
            "    raise PandasAIApiCallError(data[\"message\"])\n",
            "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, I was not able to answer your question, because of the following error:\\n\\nUnauthorized\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SmartDatalake\n",
        "\n",
        "Sometimes, you might want to work with multiple dataframes at a time, letting the LLM orchestrate which one(s) to use to answer your queries. In such cases, instead of using a `SmartDataframe` you should rather use a `SmartDatalake`.\n",
        "\n",
        "The concept is very similar to the `SmartDataframe`, but instead of accepting only 1 df as input, it can accept multiple ones."
      ],
      "metadata": {
        "id": "JvFf3OQPJ2T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai import SmartDatalake"
      ],
      "metadata": {
        "id": "Xf-q8r35KYL1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, in this example, we are provided with 2 different dfs.\n",
        "In the first one, it's reported for each employee, an employee id, a name and a department.\n",
        "In the second one, instad, it's provided the employee id and the salary for each employee.\n",
        "\n",
        "Asking PandasAI, it will join the 2 different dataframes by id and figure out the name of the one that is paid the most."
      ],
      "metadata": {
        "id": "yX3Ph1yYKfst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employees_df = pd.DataFrame(\n",
        "    {\n",
        "        \"EmployeeID\": [1, 2, 3, 4, 5],\n",
        "        \"Name\": [\"John\", \"Emma\", \"Liam\", \"Olivia\", \"William\"],\n",
        "        \"Department\": [\"HR\", \"Sales\", \"IT\", \"Marketing\", \"Finance\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "salaries_df = pd.DataFrame(\n",
        "    {\n",
        "        \"EmployeeID\": [1, 2, 3, 4, 5],\n",
        "        \"Salary\": [5000, 6000, 4500, 7000, 5500],\n",
        "    }\n",
        ")\n",
        "\n",
        "lake = SmartDatalake([employees_df, salaries_df])\n",
        "lake.chat(\"What's the name of the employee that gets paid the most?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "3GIglds_KbHo",
        "outputId": "c0b109f0-9636-4b77-9546-5b2f4ea9f35b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Unauthorized\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/bamboo_llm.py\", line 18, in call\n",
            "    response = self._session.post(\"/llm/chat\", json=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 37, in post\n",
            "    return self.make_request(\"POST\", path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 71, in make_request\n",
            "    raise PandasAIApiCallError(data[\"message\"])\n",
            "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, I was not able to answer your question, because of the following error:\\n\\nUnauthorized\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of the code that is generated:"
      ],
      "metadata": {
        "id": "FVElosbbK-_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lake.last_code_executed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyaxD4N4LEl2",
        "outputId": "ec421dd6-a8c7-45c0-b38b-bed67e66dbcf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok in this case it was easy: both the tables are share a common value called `EmployeeID`, right?\n",
        "\n",
        "Let's try with something more complex"
      ],
      "metadata": {
        "id": "wr-xjtHvMf_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = pd.DataFrame(\n",
        "    {\n",
        "        \"id\": [1, 2, 3, 4, 5],\n",
        "        \"name\": [\"John\", \"Emma\", \"Liam\", \"Olivia\", \"William\"]\n",
        "    }\n",
        ")\n",
        "users = SmartDataframe(users_df, name=\"users\")\n",
        "\n",
        "photos_df = pd.DataFrame(\n",
        "    {\n",
        "        \"id\": [31, 32, 33, 34, 35],\n",
        "        \"user_id\": [1, 1, 2, 4, 5]\n",
        "    }\n",
        ")\n",
        "photos = SmartDataframe(photos_df, name=\"photos\")\n",
        "\n",
        "lake = SmartDatalake([users, photos])\n",
        "lake.chat(\"How many photos has been uploaded by John?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "VjJc8HH9MfNH",
        "outputId": "4b63399a-9e9a-4982-b26e-6ecb311413c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Unauthorized\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/bamboo_llm.py\", line 18, in call\n",
            "    response = self._session.post(\"/llm/chat\", json=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 37, in post\n",
            "    return self.make_request(\"POST\", path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/helpers/request.py\", line 71, in make_request\n",
            "    raise PandasAIApiCallError(data[\"message\"])\n",
            "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, I was not able to answer your question, because of the following error:\\n\\nUnauthorized\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we provided for each df a table name, so that the LLM has some context and can better perform the joins. As you can see on the example below, it succeeded at figuring out the right join to do. In fact, the user \"John\" has actually 2 photos."
      ],
      "metadata": {
        "id": "pstO0KLvNjK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lake.last_code_executed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KNnAKWyNenA",
        "outputId": "c4e0461c-1768-4ba2-8277-3b0e692eb511"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different LLMs\n",
        "\n",
        "Although at the moment OpenAI GPT3.5 and GPT4 are the recommended models, we also support other models, like AzureOpenAI.\n",
        "\n",
        "You can use them as if follows:"
      ],
      "metadata": {
        "id": "AKaXv9VApKF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai import SmartDataframe\n",
        "from pandasai.llm import OpenAI\n",
        "from pandasai.llm import AzureOpenAI\n",
        "from pandasai.llm import GoogleVertexAI\n",
        "\n",
        "openai_llm = OpenAI(\n",
        "    api_token=\"my-openai-api-key\",\n",
        ")\n",
        "\n",
        "azure_llm = AzureOpenAI(\n",
        "    api_token=\"my-azure-openai-api-key\",\n",
        "    azure_endpoint=\"my-azure-openai-api-endpoint\",\n",
        "    api_version=\"2023-05-15\",\n",
        "    deployment_name=\"my-deployment-name\"\n",
        ")\n",
        "\n",
        "vertexai_llm = GoogleVertexAI(\n",
        "  project_id=\"generative-ai-training\",\n",
        "  location=\"us-central1\",\n",
        "  model=\"text-bison@001\"\n",
        ")\n",
        "\n",
        "df1 = SmartDataframe(df, config={\"llm\": openai_llm})\n",
        "df2 = SmartDataframe(df, config={\"llm\": azure_llm})\n",
        "df3 = SmartDataframe(df, config={\"llm\": vertexai_llm})\n",
        "\n",
        "print(df1.chat(\"Which country has the highest GDP?\"))\n",
        "print(df2.chat(\"Which one is the unhappiest country?\"))\n",
        "print(df3.chat(\"What is the sum of the GDP of the 2 unhappiest countries?\"))"
      ],
      "metadata": {
        "id": "qMYya2bZpJCp",
        "outputId": "8e93aaa6-bae4-4b45-fe6a-42557672ceb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Error code: 401 - {'error': {'message': 'Incorrect API key provided: my-opena*****-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 391, in call\n",
            "    self.chat_completion(self.last_prompt, memory)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 365, in chat_completion\n",
            "    response = self.client.create(**params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 742, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1277, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 954, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1058, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: my-opena*****-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n",
            "Unfortunately, I was not able to answer your question, because of the following error:\n",
            "\n",
            "Error code: 401 - {'error': {'message': 'Incorrect API key provided: my-opena*****-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 3: Connection error.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\", line 167, in handle_request\n",
            "    raise UnsupportedProtocol(\n",
            "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 990, in _request\n",
            "    response = self._client.send(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 926, in send\n",
            "    response = self._send_handling_auth(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
            "    with map_httpcore_exceptions():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
            "    raise mapped_exc(message) from exc\n",
            "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\", line 167, in handle_request\n",
            "    raise UnsupportedProtocol(\n",
            "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 990, in _request\n",
            "    response = self._client.send(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 926, in send\n",
            "    response = self._send_handling_auth(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
            "    with map_httpcore_exceptions():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
            "    raise mapped_exc(message) from exc\n",
            "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
            "    resp = self._pool.handle_request(req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\", line 167, in handle_request\n",
            "    raise UnsupportedProtocol(\n",
            "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 990, in _request\n",
            "    response = self._client.send(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 926, in send\n",
            "    response = self._send_handling_auth(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
            "    response = self._send_handling_redirects(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
            "    response = self._send_single_request(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
            "    response = transport.handle_request(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
            "    with map_httpcore_exceptions():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
            "    raise mapped_exc(message) from exc\n",
            "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
            "    ).run(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
            "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 201, in generate_code\n",
            "    response = self.call(instruction, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 391, in call\n",
            "    self.chat_completion(self.last_prompt, memory)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/llm/base.py\", line 365, in chat_completion\n",
            "    response = self.client.create(**params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 742, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1277, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 954, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1014, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1014, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1092, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1024, in _request\n",
            "    raise APIConnectionError(request=request) from err\n",
            "openai.APIConnectionError: Connection error.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n",
            "Unfortunately, I was not able to answer your question, because of the following error:\n",
            "\n",
            "Connection error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x782543659540>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x782543659540>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x782543659540>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x782543659540>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365bcd0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365bcd0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365bac0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365bac0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365a8c0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365a8c0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x782543659cf0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x782543659cf0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x782543e07670>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365b790>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x78254365b790>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain LLMs"
      ],
      "metadata": {
        "id": "cPweiIeKqrXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, you might want to use LangChain LLMs instead."
      ],
      "metadata": {
        "id": "VC8obpOBq1eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandasai[langchain]"
      ],
      "metadata": {
        "id": "kqWtvULErC73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you can use them as if they were PandasAI LLMs."
      ],
      "metadata": {
        "id": "_gMX50dXrFET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai import SmartDataframe\n",
        "from langchain.llms import OpenAI\n",
        "# from langchain.llms import Anthropic\n",
        "# from langchain.llms import LlamaCpp\n",
        "\n",
        "langchain_llm = OpenAI(openai_api_key=\"YOUR TOKEN\", max_tokens=1000)\n",
        "langchain_sdf = SmartDataframe(df, config={\"llm\": langchain_llm})\n",
        "langchain_sdf.chat(\"Which are the top 5 countries by GPD?\")"
      ],
      "metadata": {
        "id": "kJzSEArCqtkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connectors\n",
        "\n",
        "PandasAI provides a number of connectors that allow you to connect to different data sources. These connectors are designed to be easy to use, even if you are not familiar with the data source or with PandasAI.\n",
        "\n",
        "To use a connector, you first need to install the required dependencies. You can do this by running the following command:"
      ],
      "metadata": {
        "id": "ehM7uOydUB_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandasai[connectors]"
      ],
      "metadata": {
        "id": "rj_w3RylUdXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai.connectors import MySQLConnector, PostgreSQLConnector\n",
        "\n",
        "# With a MySQL database\n",
        "loan_connector = MySQLConnector(\n",
        "    config={\n",
        "        \"host\": \"localhost\",\n",
        "        \"port\": 3306,\n",
        "        \"database\": \"mydb\",\n",
        "        \"username\": \"root\",\n",
        "        \"password\": \"root\",\n",
        "        \"table\": \"loans\",\n",
        "        \"where\": [\n",
        "            # this is optional and filters the data to\n",
        "            # reduce the size of the dataframe\n",
        "            [\"loan_status\", \"=\", \"PAIDOFF\"],\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "# With a PostgreSQL database\n",
        "payment_connector = PostgreSQLConnector(\n",
        "    config={\n",
        "        \"host\": \"localhost\",\n",
        "        \"port\": 5432,\n",
        "        \"database\": \"mydb\",\n",
        "        \"username\": \"root\",\n",
        "        \"password\": \"root\",\n",
        "        \"table\": \"payments\",\n",
        "        \"where\": [\n",
        "            # this is optional and filters the data to\n",
        "            # reduce the size of the dataframe\n",
        "            [\"payment_status\", \"=\", \"PAIDOFF\"],\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "df_connector = SmartDatalake([loan_connector, payment_connector])\n",
        "response = df_connector.chat(\"How many loans from the United states?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "KF23V1fdVeXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai.connectors.yahoo_finance import YahooFinanceConnector\n",
        "from pandasai import SmartDataframe\n",
        "\n",
        "yahoo_connector = YahooFinanceConnector(\"NVDA\")\n",
        "df = SmartDataframe(yahoo_connector)\n",
        "\n",
        "response = df.chat(\"What is the closing price for yesterday?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "MrTYJHxDUBhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yahoo_connector = YahooFinanceConnector(\"NVDA\")\n",
        "\n",
        "df_connector = SmartDataframe(yahoo_connector)\n",
        "response = df_connector.chat(\"Plot the chart of the stock\")"
      ],
      "metadata": {
        "id": "Svy1neJBVx86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent\n",
        "\n",
        "The agent is very similar to the SmartDatalake, as it accepts multiple dataframes or connectors. However, it comes with a memory, therefore can be used for multi-turn conversation."
      ],
      "metadata": {
        "id": "nttPf8lpdmeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai import Agent\n",
        "\n",
        "yahoo_connector = YahooFinanceConnector(\"TSLA\")\n",
        "\n",
        "agent = Agent(yahoo_connector)\n",
        "response = agent.chat(\"Plot the chart of the stock close price\")"
      ],
      "metadata": {
        "id": "mwmaTfwNdj_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try with a follow up question"
      ],
      "metadata": {
        "id": "lF5rb4u2eLO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.chat(\"Can you add the moving average at 200 days?\")"
      ],
      "metadata": {
        "id": "Hix4KX-FeIDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.chat(\"Can you also add the moving average at 1000 days?\")"
      ],
      "metadata": {
        "id": "rDsYpCguebTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.chat(\"Can you make the price line red?\")"
      ],
      "metadata": {
        "id": "4J5Od6E0eohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find more info about the connectors (and many more connectors) here: https://docs.pandas-ai.com/en/latest/connectors/"
      ],
      "metadata": {
        "id": "_ijEXc8OVsPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train PandasAI\n",
        "You can train PandasAI to understand your data better and to improve its performance. Training is as easy as calling the `train` method on the `SmartDataframe`, `SmartDatalake` or `Agent`.\n",
        "\n",
        "There are two kinds of training:\n",
        "\n",
        "- instructions training\n",
        "- q/a training"
      ],
      "metadata": {
        "id": "6XZa2UyS-XHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions training\n",
        "\n",
        "Instructions training is used to teach PandasAI how you expect it to respond to certain queries. You can provide generic instructions about how you expect the model to approach certain types of queries, and PandasAI will use these instructions to generate responses to similar queries.\n",
        "\n",
        "For example, you might want the LLM to be aware that your company's fiscal year starts in April, or about specific ways you want to handle missing data. Or you might want to teach it about specific business rules or data analysis best practices that are specific to your organization.\n",
        "\n",
        "To train PandasAI with instructions, you can use the `train` method on the `Agent`, `SmartDataframe` or `SmartDatalake`, as it follows.\n",
        "\n",
        "** NOTE **: You can get your API KEY from https://PandaBI.ai"
      ],
      "metadata": {
        "id": "NckmeoK4-gXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PANDASAI_API_KEY\"] = \"YOUR_PANDASAI_API_KEY\""
      ],
      "metadata": {
        "id": "fV7ojfdl_fXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandasai import Agent\n",
        "from pandasai.llm import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "agent = Agent(df)\n",
        "agent.train(docs=\"Exclude the US from the highest GDP\")"
      ],
      "metadata": {
        "id": "vTE1fXyo-WXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Which country has the highest GDP?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "tLl0vEz1BIBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q/A training\n",
        "\n",
        "Q/A training is used to teach PandasAI the desired process to answer specific questions, enhancing the model's performance and determinism. One of the biggest challenges with LLMs is that they are not deterministic, meaning that the same question can produce different answers at different times. Q/A training can help to mitigate this issue.\n",
        "\n",
        "To train PandasAI with Q/A, you can use the `train` method on the `Agent`, `SmartDataframe` or `SmartDatalake`, as it follows:"
      ],
      "metadata": {
        "id": "Mc-1_aEB-mKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "query = \"What are the top 5 countries by GDP?\"\n",
        "response = \"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "df = dfs[0]\n",
        "\n",
        "# Convert GDP column to numeric values\n",
        "df['gdp'] = pd.to_numeric(df['gdp'])\n",
        "\n",
        "# Sort the DataFrame by GDP in descending order\n",
        "sorted_df = df.sort_values(by='gdp', ascending=False)\n",
        "\n",
        "# Get the top 5 countries by GDP\n",
        "top_5_countries = sorted_df.head(5)\n",
        "\n",
        "# Declare result variable\n",
        "result = {\n",
        "    \"type\": \"dataframe\",\n",
        "    \"value\": top_5_countries\n",
        "}\n",
        "\"\"\"\n",
        "agent.train(queries=[query], codes=[response])"
      ],
      "metadata": {
        "id": "Cm5C9-lI-mrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"List the top 10 countries by GDP\")\n",
        "print(response)\n",
        "print(agent.last_code_generated)"
      ],
      "metadata": {
        "id": "flWks4vpF38X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}